<table style="border-collapse: collapse; width: 96.875%; height: 842px;" border="1">
    <tbody>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">Date</td>
            <td style="width: 33.2845%; height: 29px;">Topic</td>
            <td style="width: 33.2845%; height: 29px;">Notes/links</td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">01/06 (Lecture 1)</td>
            <td style="width: 33.2845%; height: 29px;">Linear models, feature space representations</td>
            <td style="width: 33.2845%; height: 29px;">Kernel functions as similarity measures on data space, binary classification. Hofmann, Scholkopf, Smola 2008; MRT 2018</td>
        </tr>
        <tr style="height: 53px;">
            <td style="width: 33.2845%; height: 53px;">01/08 (Lecture 2)</td>
            <td style="width: 33.2845%; height: 53px;">Linear models for binary classification, perceptron algorithm</td>
            <td style="width: 33.2845%; height: 53px;">Introducing kernels into mean-based classifier; perceptron convergence under linear separability</td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">01/13 (Lecture 3)</td>
            <td style="width: 33.2845%; height: 29px;">Kernel perceptron and margin theory</td>
            <td style="width: 33.2845%; height: 29px;">Code set up for perceptron. Exercise is to kernelize the perceptron; see toy_classification.py</td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">01/15 (Lecture 4)</td>
            <td style="width: 33.2845%; height: 29px;">Mercer's theorem, representer theorem, RKHS</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 55px;">
            <td style="width: 33.2845%; height: 55px;">01/20 (Lecture 5)</td>
            <td style="width: 33.2845%; height: 55px;">Kernel SVM, generalization</td>
            <td style="width: 33.2845%; height: 55px;"></td>
        </tr>
        <tr style="height: 53px;">
            <td style="width: 33.2845%; height: 53px;">01/22 (Lecture 6)</td>
            <td style="width: 33.2845%; height: 53px;">More on kernel regression, kernel trick</td>
            <td style="width: 33.2845%; height: 53px;"></td>
        </tr>
        <tr style="height: 53px;">
            <td style="width: 33.2845%; height: 53px;">01/27 (Lecture 7) -&gt; 01/30</td>
            <td style="width: 33.2845%; height: 53px;">Kernel function spaces, examples</td>
            <td style="width: 33.2845%; height: 53px;"></td>
        </tr>
        <tr style="height: 101px;">
            <td style="width: 33.2845%; height: 101px;">01/29 (Lecture 8) -&gt; 01/31</td>
            <td style="width: 33.2845%; height: 101px;">Kernels in sampling, independence tests, conditional sampling, density estimation</td>
            <td style="width: 33.2845%; height: 101px;"></td>
        </tr>
        <tr style="height: 53px;">
            <td style="width: 33.2845%; height: 53px;">02/03 (Lecture 9)</td>
            <td style="width: 33.2845%; height: 53px;">Kernels in generative modeling, kernel PCA</td>
            <td style="width: 33.2845%; height: 53px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">02/05 (Lecture 10)</td>
            <td style="width: 33.2845%; height: 29px;">Deep learning theory and kernel regression -- NTK</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 53px;">
            <td style="width: 33.2845%; height: 53px;">02/10 (Lecture 11)</td>
            <td style="width: 33.2845%; height: 53px;">Deep learning theory and kernel regression -- NTK</td>
            <td style="width: 33.2845%; height: 53px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">02/12 (Lecture 12)</td>
            <td style="width: 33.2845%; height: 29px;">Learning kernels, kernel design</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 53px;">
            <td style="width: 33.2845%; height: 53px;">02/17 (Lecture 13)</td>
            <td style="width: 33.2845%; height: 53px;">Kernels in PDEs, kernels in dynamical systems</td>
            <td style="width: 33.2845%; height: 53px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">02/19 (Lecture 14)</td>
            <td style="width: 33.2845%; height: 29px;">Student paper - I</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">02/24 (Lecture 15)</td>
            <td style="width: 33.2845%; height: 29px;">Student paper - II</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">02/26 (Lecture 16)</td>
            <td style="width: 33.2845%; height: 29px;">Student paper - III</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">03/03</td>
            <td style="width: 33.2845%; height: 29px;">Student presentations - I</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">03/05 -&gt; 02/28</td>
            <td style="width: 33.2845%; height: 29px;">Student presentations - II</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 29px;">
            <td style="width: 33.2845%; height: 29px;">03/10</td>
            <td style="width: 33.2845%; height: 29px;">Students presentations - III</td>
            <td style="width: 33.2845%; height: 29px;"></td>
        </tr>
        <tr style="height: 5px;">
            <td style="width: 33.2845%; height: 5px;"></td>
            <td style="width: 33.2845%; height: 5px;"></td>
            <td style="width: 33.2845%; height: 5px;"></td>
        </tr>
        <tr style="height: 10px;">
            <td style="width: 33.2845%; height: 10px;"></td>
            <td style="width: 33.2845%; height: 10px;"></td>
            <td style="width: 33.2845%; height: 10px;"></td>
        </tr>
        <tr style="height: 5px;">
            <td style="width: 33.2845%; height: 5px;"></td>
            <td style="width: 33.2845%; height: 5px;"></td>
            <td style="width: 33.2845%; height: 5px;"></td>
        </tr>
    </tbody>
</table>
<p>&nbsp;</p>
<p><span style="font-size: 24pt;">References</span></p>
<p><span style="font-size: 14pt;">1.&nbsp; <a class="inline_disabled" href="https://probml.github.io/pml-book/book2.html" target="_blank" rel="noopener">Probabilistic Machine Learning,</a> Kevin Murphy, 2024</span></p>
<p><span style="font-size: 14pt;">2. <a class="inline_disabled" href="https://cs.nyu.edu/~mohri/mlbook/" target="_blank" rel="noopener">Foundations of Machine Learning</a>, Mohri, Rohstamizadeh, Talwalkar, 2018 (MRT 2018)<br /></span></p>
<p><span style="font-size: 14pt;">3. Haussler, David. <a class="inline_disabled" title="Link" href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac" target="_blank" rel="noopener">Convolution kernels on discrete structures.</a>Vol. 646. Technical report, Department of Computer Science, University of California at Santa Cruz, 1999.</span></p>
<p><span style="font-size: 14pt;">4.&nbsp; <a class="inline_disabled" href="https://projecteuclid.org/journals/annals-of-statistics/volume-36/issue-3/Kernel-methods-in-machine-learning/10.1214/009053607000000677.full" target="_blank" rel="noopener">Kernel methods in machine learning</a>, Hofmann, Scholkopf, Smola, 2008</span></p>
<p><span style="font-size: 14pt;">5. &nbsp;Aronszajn, N. <a class="inline_disabled" href="https://doi.org/10.2307/1990404" target="_blank" rel="noopener">Theory of reproducing kernels</a>. <i>Trans. Amer. Math. Soc</i>. 1950</span></p>
<p><span style="font-size: 14pt;">6. Rasmussen, C. E. and Williams, C. K. I. <a class="inline_disabled" title="Link" href="https://research-ebsco-com.proxy.uchicago.edu/c/ijaglh/search/details/qmxeq2d4r5?db=e000xna" target="_blank" rel="noopener">Gaussian Processes for Machine Learning.</a>2006 </span></p>
<p><span style="font-size: 14pt;">7. Sch&ouml;lkopf, B. and Smola, A. <a class="inline_disabled" href="https://direct.mit.edu/books/monograph/1821/Learning-with-KernelsSupport-Vector-Machines" target="_blank" rel="noopener"><i>Learning with Kernels</i>.</a> 2002</span></p>
<p><span style="font-size: 14pt;">8. Nelson and Stuart. <a class="inline_disabled" href="https://epubs.siam.org/doi/abs/10.1137/24M1648703" target="_blank" rel="noopener">Operator learning using random features: a tool for scientific computing</a> 2024</span></p>
<p><span style="font-size: 14pt;">9. Lorenz, Edward N. <a class="inline_disabled" href="https://journals.ametsoc.org/downloadpdf/journals/atsc/26/4/1520-0469_1969_26_636_aparbn_2_0_co_2.pdf" target="_blank" rel="noopener">Atmospheric predictability as revealed by naturally occurring analogues</a>. <i>Journal of Atmospheric Sciences</i> 26, no. 4 (1969): 636-646.</span></p>
<p><span style="font-size: 14pt;">10. Alexander, Romeo, and Dimitrios Giannakis. <a class="inline_disabled" href="https://www.sciencedirect.com/science/article/pii/S016727891930377X" target="_blank" rel="noopener">Operator-theoretic framework for forecasting nonlinear time series with kernel analog techniques.</a><i> Physica D: Nonlinear Phenomena</i> 409 (2020): 132520.</span></p>
<p><span style="font-size: 14pt;">11. Wilson, Andrew, and Ryan Adams. <a class="inline_disabled" href="http://proceedings.mlr.press/v28/wilson13.html" target="_blank" rel="noopener">Gaussian process kernels for pattern discovery and extrapolation</a>.&nbsp; In <i>International conference on machine learning</i>, pp. 1067-1075. PMLR, 2013</span></p>
<p><span style="font-size: 14pt;">12. Chen, Hosseini, Owhadi and Stuart. <a class="inline_disabled" href="https://www.sciencedirect.com/science/article/pii/S0021999121005635" target="_blank" rel="noopener">Solving and learning nonlinear PDEs with Gaussian processes.</a> J. Comp. Phys. 2021</span></p>
<p><span style="font-size: 14pt;">13.&nbsp; Owhadi and Yoo. <a class="inline_disabled" href="https://www.sciencedirect.com/science/article/pii/S0021999119302232" target="_blank" rel="noopener">Kernel flows: from learning kernels from data into the abyss</a>. J. Comp. Phys. 2019</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
